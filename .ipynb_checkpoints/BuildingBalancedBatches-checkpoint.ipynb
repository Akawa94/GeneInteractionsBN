{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import gc\n",
    "import os\n",
    "import copy\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory='../GeneInteractionsBN_Datasets/Balanced_Batches'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LEF1_Target.csv', 'MYC_Target.csv', 'Erk_Target.csv', 'Ikk2_Target.csv', 'IRF4_Target.csv', 'CTNNB1_Target.csv', 'Jnk_Target.csv']\n",
      "../GeneInteractionsBN_Datasets/Labeled/MYC_Target.csv\n",
      "64002\n",
      "64002\n",
      "../GeneInteractionsBN_Datasets/Labeled/Erk_Target.csv\n",
      "140730\n",
      "204732\n",
      "../GeneInteractionsBN_Datasets/Labeled/Ikk2_Target.csv\n",
      "108984\n",
      "313716\n",
      "../GeneInteractionsBN_Datasets/Labeled/IRF4_Target.csv\n",
      "96654\n",
      "410370\n",
      "../GeneInteractionsBN_Datasets/Labeled/CTNNB1_Target.csv\n"
     ]
    }
   ],
   "source": [
    "# Dat Size and proportions\n",
    "#files = pd.DataFrame(np.random.randn(10, 5), columns=['a', 'b', 'c', 'd', 'e'])\n",
    "folder = 'Tt'\n",
    "directory = '../GeneInteractionsBN_Datasets/Labeled/'\n",
    "for filename_same in os.listdir(directory):\n",
    "    data_list = {}\n",
    "    total_size = 0\n",
    "    censored_listdir = copy.deepcopy(os.listdir(directory))\n",
    "    print(censored_listdir)\n",
    "    censored_listdir.pop(censored_listdir.index(filename_same)) # Censoring one for testing\n",
    "    save_folder = '../GeneInteractionsBN_Datasets/Batches/'+'censored_'+filename_same.split('.')[0]+'/'\n",
    "    for filename in censored_listdir:\n",
    "        if filename.endswith(\".csv\"): \n",
    "            print(os.path.join(directory, filename))\n",
    "            csv = pd.read_csv(filepath_or_buffer=os.path.join(directory, filename),sep=',')\n",
    "            key_name = filename.split('.')[0].split('_')[0]\n",
    "            data_list[key_name]=[0,[]]\n",
    "            #print(csv['Target'][0])\n",
    "            for i in range(0,len(csv)):\n",
    "                value = int(csv['Target'][i])\n",
    "                if (value==1 or value==0):\n",
    "                    # data_list[key_name][1][0] for index\n",
    "                    # data_list[key_name][1][2] for marker\n",
    "                    data_list[key_name][1].append([i,value,0])\n",
    "                    data_list[key_name][0]=data_list[key_name][0]+1\n",
    "            #print(key_name)\n",
    "            #print(data_list[key_name])\n",
    "            total_size = total_size + data_list[key_name][0]\n",
    "            print(data_list[key_name][0])\n",
    "            print(total_size)\n",
    "            del csv\n",
    "            gc.collect()\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "    extract_directory = '../GeneInteractionsBN_Datasets/DataGeneCausality/'+folder+'/'\n",
    "    batch_size = 6000\n",
    "    #balancing the datalist\n",
    "    total_size=0\n",
    "    for key in data_list:\n",
    "        pos_count=0\n",
    "        neg_count=0\n",
    "        for i in data_list[key][1]:\n",
    "            if i[1]==1:\n",
    "                pos_count+=1\n",
    "            if i[1]==0:\n",
    "                neg_count+=1\n",
    "        while pos_count<neg_count:\n",
    "            pop_index=randint(0,pos_count+neg_count-1)\n",
    "            if (data_list[key][1][pop_index][1]==0):\n",
    "                data_list[key][1][pop_index][1].pop()\n",
    "                neg_count-=1\n",
    "        data_list[key][0]=pos_count*2 # now will have same positives as negatives\n",
    "        total_size+=data_list[key][0]\n",
    "    n_loops = int(total_size/batch_size)\n",
    "    print(n_loops)\n",
    "    print(total_size)\n",
    "#     for i in range(0,n_loops):\n",
    "#         csv_output = []\n",
    "#         for filename in os.listdir(extract_directory):\n",
    "#             if filename.endswith(\".csv\"):\n",
    "#                 print(os.path.join(extract_directory, filename))\n",
    "#                 csv = pd.read_csv(filepath_or_buffer=os.path.join(extract_directory, filename),sep=';')\n",
    "#                 pd_headers = csv.columns.insert(0,'TrueIndex')\n",
    "#                 key_name = filename.split('.')[0]\n",
    "#                 try:\n",
    "#                     contribution_size = int(data_list[key_name][0]*batch_size/total_size)\n",
    "#                 except:\n",
    "#                     contribution_size = 0\n",
    "#                 print(contribution_size)\n",
    "#                 while contribution_size>0:\n",
    "#                     chosen_index = randint(0, data_list[key_name][0]-1)\n",
    "#                     # data_list[key_name][1][i][0] for index\n",
    "#                     # data_list[key_name][1][i][2] for marker\n",
    "#                     if data_list[key_name][1][chosen_index][2] == 0: # proceeds\n",
    "#                         data_list[key_name][1][chosen_index][2] = 1 # sets marker\n",
    "#                         contribution_size = contribution_size-1\n",
    "#                         # inserting first the true index and then the values\n",
    "#                         csv_output.append(np.insert(csv.iloc[data_list[key_name][1][chosen_index][0],:].values,0,data_list[key_name][1][chosen_index][0]))\n",
    "#                 del csv\n",
    "#                 gc.collect()\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 continue\n",
    "#         df = pd.DataFrame(data=csv_output,columns=pd_headers)\n",
    "#         if not os.path.exists(save_folder):\n",
    "#             os.makedirs(save_folder)\n",
    "#         df.to_csv(save_folder+'batch_'+str(i)+'.csv')\n",
    "#         del csv_output\n",
    "#         del df\n",
    "#     del data_list\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767488\n"
     ]
    }
   ],
   "source": [
    "marked = 0\n",
    "for key in data_list:\n",
    "    for i in data_list[key][1]:\n",
    "        if i[2]==1:\n",
    "            marked=marked+1\n",
    "print(marked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

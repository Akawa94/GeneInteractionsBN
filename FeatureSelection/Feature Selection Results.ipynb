{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.stats import chi2\n",
    "from math import floor\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.svm import LinearSVC\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support as full_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory=\"/home/sdelrio/alarm_datasets/log_results/mmpc_partitioned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recovering results\n",
    "# recovery_files = ['/scored_true-mb_log.txt',\n",
    "#                   '/scored_entropy-mi_log.txt',\n",
    "#                   '/scored_ttest_log.txt',\n",
    "#                   '/scored_supercpc_log.txt'\n",
    "#                  ]\n",
    "recovery_files = ['/scored_svm_entropy-mi_log.txt',\n",
    "                  #'/scored_nb_entropy-mi_log.txt',\n",
    "                  '/scored_svm_supercpc_log.txt',\n",
    "                  #'/scored_nb_ttest_log.txt',\n",
    "                  '/scored_svm_ttest_log.txt',\n",
    "                  #'/scored_nb_supercpc_log.txt',\n",
    "                  '/scored_svm_true-pc_log.txt',\n",
    "                  #'/scored_nb_true-pc_log.txt',\n",
    "                  '/scored_svm_true-mb_log.txt',\n",
    "                  #'/scored_nb_true-mb_log.txt'\n",
    "                 ]\n",
    "recovery_arr = []\n",
    "for f_name in recovery_files:\n",
    "    ff = open(log_directory+f_name,'r')\n",
    "    #line_rec_scor =  ff.read().split('\\n')[0].split(';')\n",
    "    recovery_scored_file=[]\n",
    "    for line in ff.read().split('\\n'):\n",
    "        line_arr=[]\n",
    "        line_rec_scor=line.split(';')\n",
    "        node_dict={}\n",
    "        if (len(line_rec_scor[0])==0):\n",
    "            continue\n",
    "        node_dict['TargetNode']=line_rec_scor[1]\n",
    "        node_dict['supercpc']=line_rec_scor[2].split('_')\n",
    "        node_dict['class_precisions']=[]\n",
    "        line_arr.append(line_rec_scor[0])\n",
    "        \n",
    "        for i in range(0,len(line_rec_scor[3].split('_')),4):\n",
    "            if (len(line_rec_scor[3].split('_')[i:i+3][0])==0):\n",
    "                continue\n",
    "            acc_arr=[]\n",
    "            #print(line_rec_scor[3])\n",
    "            acc_arr.append([float(x) for x in line_rec_scor[3].split('_')[i+3].split('\\t')[:3]])\n",
    "            try:\n",
    "                acc_arr.append([float(x) for x in line_rec_scor[3].split('_')[i+3].split('\\t')[3:6]])\n",
    "            except:\n",
    "                print(line_rec_scor[3].split('_')[i+3].split('\\t')[3:6])\n",
    "            node_dict['class_precisions'].append([acc_arr,line_rec_scor[3].split('_')[i]+'_'+line_rec_scor[3].split('_')[i+1]+'_'+line_rec_scor[3].split('_')[i+2]])\n",
    "        line_arr.append(node_dict)\n",
    "        recovery_scored_file.append(line_arr)\n",
    "    recovery_arr.append([f_name,recovery_scored_file])\n",
    "    ff.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recovering preselected nodes\n",
    "main_directory= '/home/sdelrio/alarm_datasets/Alarm10/'\n",
    "save_folder='/home/sdelrio/alarm_datasets/log_results/'\n",
    "\n",
    "if not os.path.exists(main_directory):\n",
    "    print(\"Bad routing.\")\n",
    "preselected_nodes=[] # will have [node_str,balance_ranking]\n",
    "# so far, we need Node, size of estimated pc set per filename, balance ranking\n",
    "ff = open(save_folder+'mmpc_partitioned/alarm10_binary_nodes_selected.txt','r')\n",
    "for e in ff.read().split('\\n'):\n",
    "    spl_line = e.split(';')\n",
    "    if (len(spl_line[0])==0):\n",
    "        continue\n",
    "    preselected_nodes.append([spl_line[0],float(spl_line[1])])\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing results\n",
    "sample_sizes = ['s500','s1000','s5000']\n",
    "\n",
    "balance_ranking = []\n",
    "\n",
    "for results_arr in recovery_arr:\n",
    "    test_name = results_arr[0].split('_log')[0]\n",
    "    for sample_size in sample_sizes:\n",
    "        bl_sorted = sorted([x for x in results_arr[1]\n",
    "                               if x[0].split('_')[1] == sample_size],\\\n",
    "                           key=lambda x: x[1]['TargetNode'])\n",
    "        evaluated_nodes = []\n",
    "        \n",
    "        for e in bl_sorted:\n",
    "            if ('@' in e[1]['TargetNode']):\n",
    "                e[1]['TargetNode']=e[1]['TargetNode'].split('@')[0]\n",
    "            \n",
    "            if (e[1]['TargetNode'] in evaluated_nodes) or\\\n",
    "                (e[1]['TargetNode'] not in [x[0].split('@')[0] for x in preselected_nodes]):\n",
    "                continue\n",
    "            \n",
    "            print('Retrieving results from test '+test_name+', Target '+e[1]['TargetNode']+', with sample size of '+sample_size)\n",
    "            evaluated_nodes.append(e[1]['TargetNode'])\n",
    "            \n",
    "            b_rank = [x[1] for x in preselected_nodes if x[0].split('@')[0]==e[1]['TargetNode']][0]\n",
    "            g_rank = []\n",
    "            for sub_e in [x for x in bl_sorted if x[1]['TargetNode'] == e[1]['TargetNode']]:\n",
    "                for prec in sub_e[1]['class_precisions']:\n",
    "                    g_rank.append(g_mean(prec[0]))\n",
    "            balance_ranking.append([test_name,sample_size,e[1]['TargetNode'],b_rank,sum(g_rank)/len(g_rank)])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing and making graphic of results\n",
    "\n",
    "%matplotlib inline\n",
    "\"\"\"\n",
    "Plotting a three-way ANOVA\n",
    "==========================\n",
    "\n",
    "_thumb: .42, .5\n",
    "\"\"\"\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Creating the df\n",
    "df = pd.DataFrame(columns=[\"Balance Rank\", \"G-mean\",\"Feature Selection Method\",\"Number of samples\"])\n",
    "\n",
    "# sumarizing data for intervals of 0.25\n",
    "\n",
    "ticks_step = 0.15\n",
    "step_top = 0.60\n",
    "\n",
    "steps_arr = np.arange(0.0,step_top,ticks_step)\n",
    "\n",
    "size_label = []\n",
    "\n",
    "for i in range(0,len(steps_arr)):\n",
    "    #print(steps_arr[i])\n",
    "    size_label.append(len([x for x in balance_ranking \n",
    "                           if x[0]==recovery_files[0].split('_log')[0] \n",
    "                           and x[1]==sample_sizes[2]\n",
    "                           and (x[3]>=steps_arr[i]  and x[3] < steps_arr[i]+ticks_step)]))\n",
    "\n",
    "#print(size_label)\n",
    "for e in balance_ranking:\n",
    "    # calculating which range it is in\n",
    "    b_rank_counter=0\n",
    "    for b_counter in range(0,len(steps_arr)):\n",
    "        if ((steps_arr[b_counter]+ticks_step)>e[3]):\n",
    "            break\n",
    "        b_rank_counter=b_rank_counter+1\n",
    "    \n",
    "    df = df.append({\n",
    "             \"Balance Rank\":str(math.ceil(100*steps_arr[b_rank_counter])/100) +\n",
    "                                ' - ' + \n",
    "                            str(math.ceil(100*(steps_arr[b_rank_counter]+ticks_step))/100)+\n",
    "                            '\\n '+str(size_label[b_rank_counter]), \n",
    "            \"G-mean\":e[4],\n",
    "            \"Feature Selection Method\":e[0],\n",
    "            \"Number of samples\":int(e[1].split('s')[1])\n",
    "              }, ignore_index=True)\n",
    "# Draw a pointplot to show pulse as a function of three categorical factors\n",
    "sns.set_color_codes(\"pastel\")\n",
    "g = sns.factorplot(x=\"Balance Rank\", y=\"G-mean\", hue=\"Feature Selection Method\",\n",
    "                   col=\"Number of samples\", data=df,\n",
    "                   capsize=.2, palette=\"YlGnBu_d\", size=7, aspect=1.5)\n",
    "\n",
    "g.despine(left=True)\n",
    "\n",
    "g.set(yticks=np.arange(0.0,1.0,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_scoring(size1, size2):\n",
    "    f_size1 = float(size1)\n",
    "    f_size2 = float(size2)\n",
    "    if (f_size1/f_size2 <= 1):\n",
    "        return f_size1/f_size2\n",
    "    else:\n",
    "        return f_size2/f_size1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_mean(precision_arr):\n",
    "    counter=1\n",
    "    for e in precision_arr:\n",
    "        counter=counter*e[2]\n",
    "    \n",
    "    return counter**(1/len(precision_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

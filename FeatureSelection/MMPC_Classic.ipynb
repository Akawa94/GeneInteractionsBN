{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.stats import chi2\n",
    "from math import floor\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial data setup\n",
    "\n",
    "X = pd.read_csv(\"/home/a20114261/GeneInteractions/GeneInteractionsBN_Datasets/Balanced_Batches/censored_Erk_Target/batch_0.csv\")\n",
    "\n",
    "# each cell can be -1, 0 or 1\n",
    "#Pre-processing data\n",
    "#X['Pvalue']=list(map(lambda x: 1 if x<=0.01 else (0 if x>=0.5 else -1), X['Pvalue']))\n",
    "X['Pvalue']=list(map(lambda x: 1 if x<=0.05 else 0, X['Pvalue']))\n",
    "del X['Unnamed: 0']\n",
    "del X['TrueIndex']\n",
    "del X['CauseGene']\n",
    "del X['EffectGene']\n",
    "del X['Replicate']\n",
    "del X['Treatment']\n",
    "PC=[]\n",
    "for column in X:\n",
    "    if (column != \"Pvalue\"):\n",
    "        X[column] = list(map(lambda x: x+1 , X[column]))\n",
    "x_heads = []\n",
    "for i in range(0,len(X.keys())):\n",
    "    max_v=1\n",
    "    for row in X[X.keys()[i]]:\n",
    "        if (row>max_v-1):\n",
    "            max_v+=row-(max_v-1)\n",
    "    save_i=i+1\n",
    "    x_heads.append(\"Node\"+str(save_i)+\"@\"+str(max_v))\n",
    "X.columns = x_heads\n",
    "data_c_size = len(X[X.keys()[1]])\n",
    "data_vars = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a20114261/anaconda3/envs/GeneInteractionsBN/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(\"/home/a20114261/Alarm1_s5000_v1.txt\",delimiter='  ',header=None)\n",
    "x_heads = []\n",
    "for i in range(0,len(X.keys())):\n",
    "    max_v=1\n",
    "    for row in X[X.keys()[i]]:\n",
    "        if (row>max_v-1):\n",
    "            max_v+=row-(max_v-1)\n",
    "    save_i=i+1\n",
    "    x_heads.append(\"Node\"+str(save_i)+\"@\"+str(max_v))\n",
    "X.columns = x_heads\n",
    "data_c_size = len(X[X.keys()[1]])\n",
    "data_vars = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5997"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initial setup for TensorFlow\n",
    "with tf.device('/job:localhost/replica:0/task:0/device:GPU:1'):\n",
    "    a = tf.placeholder(tf.float32,shape=(data_c_size,))\n",
    "    b = tf.placeholder(tf.float32,shape=(data_c_size,))\n",
    "    dot_mult_op = tf.einsum('i,i->',a, b)\n",
    "    \n",
    "    c = tf.placeholder(tf.float32,shape=(data_c_size,))\n",
    "    d = tf.placeholder(tf.float32,shape=(data_c_size,))\n",
    "    var_mask = tf.equal(c,d)\n",
    "    \n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.50)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_const_vector(n,size):\n",
    "    global sess\n",
    "    with tf.device('/job:localhost/replica:0/task:0/device:GPU:1'):\n",
    "        a = tf.constant(np.zeros(size),tf.float32)\n",
    "        b = tf.constant(n,tf.float32)\n",
    "        v_constructor = a+b\n",
    "        return sess.run(v_constructor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_dot_mult(arr1,arr2):\n",
    "    global sess\n",
    "    global dot_mult_op\n",
    "    return sess.run(dot_mult_op,{a:arr1,b:arr2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_mask_var(arr1,var):\n",
    "    global sess\n",
    "    global var_mask\n",
    "    global const_vectors\n",
    "    return sess.run(var_mask,{c:arr1,d:const_vectors[var]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_mask_equal(arr1,arr2):\n",
    "    global sess\n",
    "    global var_mask\n",
    "    return sess.run(var_mask,{c:arr1,d:arr2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_const_vectors(var_arr,size):\n",
    "    returnable_dict = {}\n",
    "    for i in range(len(var_arr)):\n",
    "        returnable_dict[var_arr[i]] = tf_const_vector(var_arr[i],size)\n",
    "    \n",
    "    return returnable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExistDseparator(TargetNode,Xi, Z, X, alpha):\n",
    "    flagExist = False\n",
    "    dsepSet=[]\n",
    "    #counter=0\n",
    "    #print_names(Z)\n",
    "    for i in range(0,(2**len(Z))-1):\n",
    "        IDsubsetZ_dec = i\n",
    "        IDsubsetZ_bin = bin(IDsubsetZ_dec)\n",
    "        subsetZ = getZsubset(IDsubsetZ_bin,Z)\n",
    "        # no cache\n",
    "        #print(\"from exist dseparator\")\n",
    "        dep = Dep(TargetNode,Xi,subsetZ, X, alpha)\n",
    "        #print(subsetZ)\n",
    "        #print(dep)\n",
    "        if (dep==0):\n",
    "            flagExist = True\n",
    "            dsepSet = subsetZ\n",
    "            break\n",
    "    #print(\"Module exist d-separator: \",counter)\n",
    "    return [flagExist,dsepSet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCondValues(z, condVars):\n",
    "    if len(condVars)>1:\n",
    "        maxz = 1\n",
    "        for column in condVars:\n",
    "            maxz*=int(column['name'].split('@')[1]) # equals to prod(sizes)\n",
    "        d = np.zeros(len(condVars))\n",
    "        \n",
    "        div_dim = maxz/int(condVars[0]['name'].split('@')[1])\n",
    "        num2div = z\n",
    "        \n",
    "        for i in range(0,len(condVars)-1):\n",
    "            d[i] = floor(num2div/div_dim)\n",
    "            num2div=num2div%div_dim\n",
    "            div_dim = div_dim/int(condVars[i+1]['name'].split('@')[1])\n",
    "        d[i] = num2div\n",
    "    else:\n",
    "        d = [z]\n",
    "#     print(\"Size of condVars was: \"+str(len(condVars)))\n",
    "#     print(d)\n",
    "#     print(sum([],d))\n",
    "#     if (len(d)>1):\n",
    "#         print(d)\n",
    "#         print(z)\n",
    "#         print_names(condVars)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dep(TargetNode, Xi, CondVars, X, alpha):\n",
    "    #print('in Dep')\n",
    "    global data_c_size\n",
    "    \n",
    "    vvTarget = []\n",
    "    for i in range(int(TargetNode['name'].split('@')[1])):\n",
    "        vvTarget.append(i)\n",
    "    \n",
    "    vvXi = []\n",
    "    for i in range(int(Xi['name'].split('@')[1])):\n",
    "        vvXi.append(i)\n",
    "    \n",
    "    szCondVars = 1\n",
    "    #print(CondVars)\n",
    "    for column in CondVars:\n",
    "        #print(column)\n",
    "        szCondVars *= int(column['name'].split('@')[1])\n",
    "    \n",
    "    if data_c_size <= (5 * len(vvTarget)*len(vvXi)*(szCondVars)):\n",
    "        return 1\n",
    "    \n",
    "    if (len(CondVars)==0):\n",
    "        S = np.zeros((len(vvTarget),len(vvXi)))\n",
    "        for i in range(0,len(vvTarget)):\n",
    "            for j in range(0,len(vvXi)):\n",
    "                var1=np.array(TargetNode['data']) # Target Node\n",
    "                var2=np.array(Xi['data'])\n",
    "                # looking up for 0, 1 and 2\n",
    "                #op1 = tf_mask_var(var1,vvTarget[i])\n",
    "                op1 = np.array(list(map(lambda x: 1 if x==vvTarget[i] else 0, var1.tolist())))\n",
    "                #op2 = tf_mask_var(var2,vvXi[j])\n",
    "                op2 = np.array(list(map(lambda x: 1 if x==vvXi[j] else 0, var2.tolist())))\n",
    "                #S[i][j] = tf_dot_mult(op1,op2)\n",
    "                S[i][j]=np.sum(op1*op2)\n",
    "                #print(S[i][j])\n",
    "        G2=0\n",
    "        N = np.sum(S)\n",
    "#         print(S)\n",
    "#         print(N)\n",
    "        Si =np.sum(S,axis=1)\n",
    "        Sj =np.sum(S,axis=0)\n",
    "        Df = ((len(vvTarget)-1)*(len(vvXi)-1))\n",
    "#         print(S[np.where(S>0)])\n",
    "        Dedf = len((S[np.where(S>0)]))\\\n",
    "                      - len(Si[np.where(Si>0)])\\\n",
    "                      - len(Sj[np.where(Sj>0)]) +1\n",
    "#         print(\"Dedf before if: \",Dedf)\n",
    "        if (Dedf<1):\n",
    "            Dedf=1\n",
    "            #print('Here is the trouble')\n",
    "            #return 0\n",
    "        #print(S)\n",
    "        for i in range(0,len(vvTarget)):\n",
    "            for j in range(0,len(vvXi)):\n",
    "                #print(i)\n",
    "                #print(j)\n",
    "                if (S[i][j]>0):\n",
    "                    #print(Si[i])\n",
    "                    #print(Sj[j])\n",
    "                    G2 = G2 + S[i][j]*np.log((S[i][j])*N/(Si[i]*Sj[j]))\n",
    "                    #print(G2)\n",
    "        G2 = 2*G2\n",
    "        \n",
    "    else: # test conditional dependency\n",
    "        \n",
    "            \n",
    "        S = np.zeros((len(vvTarget),len(vvXi),szCondVars))\n",
    "        for i in range(0,len(vvTarget)):\n",
    "            for j in range(0,len(vvXi)):\n",
    "                for k in range(0,szCondVars):\n",
    "                    condValue = GetCondValues(k,CondVars)\n",
    "                    #print(condValue)\n",
    "                    flagDataCondVars = np.ones(len(Xi['data']))\n",
    "                    for l in range(0,len(CondVars)):\n",
    "                        X_l = CondVars[l]\n",
    "                        flagDataCondVars = flagDataCondVars*np.array(list(map(lambda x: 1 if x==condValue[l] else 0, X_l['data'])))\n",
    "                        #op1 = tf_mask_var(X_l['data'],condValue[l])\n",
    "                        #flagDataCondVars = np.array(list(map(lambda x: 1 if x==condValue[l] else 0, X_l.tolist())))\n",
    "                        #flagDataCondVars = flagDataCondVars*op1\n",
    "                    var1=np.array(TargetNode['data'])\n",
    "                    var2=np.array(Xi['data'])\n",
    "                    # looking up for -1, 0 and 1\n",
    "                    op1 = np.array(list(map(lambda x: 1 if x==vvTarget[i] else 0, var1.tolist())))\n",
    "                    #op1 = tf_mask_var(var1,vvTarget[i])\n",
    "                    #print(op1)\n",
    "                    #op2 = tf_mask_var(var2,vvXi[j])\n",
    "                    op2 = np.array(list(map(lambda x: 1 if x==vvXi[j] else 0, var2.tolist())))\n",
    "                    #print(op2)\n",
    "                    #print(op1*op2*flagDataCondVars)\n",
    "                    S[i][j][k]=np.sum(op1*op2*flagDataCondVars)\n",
    "        G2 = 0\n",
    "        \n",
    "        Sjk = np.sum(S,axis=0)\n",
    "        Sik = np.sum(S,axis=1)\n",
    "        Sk = np.sum(Sjk,axis=0)\n",
    "        \n",
    "        #Sjk = sum(S,1);\n",
    "        #Sik = sum(S,2);\n",
    "        #Sk = sum(Sjk,2); \n",
    "        Dedf = len(S[np.where(S>0)]) -\\\n",
    "                len(Sik[np.where(Sik>0)]) -\\\n",
    "                len(Sjk[np.where(Sjk>0)]) +\\\n",
    "                len(Sk[np.where(Sk>0)])\n",
    "        if Dedf<1:\n",
    "            Dedf=1\n",
    "            #print('No, here is the trouble')\n",
    "            #return 0\n",
    "        \n",
    "        # compute G2 statistic\n",
    "        #print(S.shape)\n",
    "        #print(Sjk.shape)\n",
    "        #print(Sik.shape)\n",
    "        #print(Sk.shape)\n",
    "        for i in range(0,len(vvTarget)):\n",
    "            for j in range(0,len(vvXi)):\n",
    "                for k in range(0,szCondVars):\n",
    "                    if (S[i][j][k]>0):\n",
    "                        #print(i,j,k)\n",
    "                        #test_op =  Sk[k]\n",
    "                        #test_op = Sik[i][k]\n",
    "                        #test_op = Sjk[j][k]\n",
    "                        G2=G2+(S[i][j][k] * np.log(\\\n",
    "                                    (S[i][j][k] * Sk[k])/\\\n",
    "                                    (Sik[i][k] * Sjk[j][k])))\n",
    "        G2 = 2*G2\n",
    "    \n",
    "    assoc = (alpha - (1 - chi2.cdf(G2,Dedf)))/alpha\n",
    "    #print(G2)\n",
    "    #print(Dedf)\n",
    "    #print(assoc)\n",
    "    if assoc<0:\n",
    "        assoc=0\n",
    "#     print(\"Target Node: \",TargetNode['name'])\n",
    "#     print(\"Node XI: \", Xi['name'])\n",
    "#     print(\"\\tG2:\",G2)\n",
    "#     print(\"\\tDedf: \",Dedf)\n",
    "#     print(\"\\tAssoc: \",assoc)\n",
    "#     print()\n",
    "#     print()\n",
    "    return assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getZsubset(bin_id,Z):\n",
    "    bin_str=str(bin_id[::-1])\n",
    "    Zsubset=[]\n",
    "    for i in range(0,len(bin_str)):\n",
    "        if bin_str[i]=='1':\n",
    "            Zsubset.append(Z[i])\n",
    "    return Zsubset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayUniverse(TargetNode,X):\n",
    "    Universe = []\n",
    "    for key in X:\n",
    "        #print(\"Key in X:\",key)\n",
    "        #print(\"Target Node is: \",TargetNode)\n",
    "        if (key!=TargetNode):\n",
    "            append_dict={'name':key,'data':X[key].copy(deep=True).tolist()}\n",
    "            Universe.append(append_dict)\n",
    "    return Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayX(X):\n",
    "    returnable=[]\n",
    "    for key in X:\n",
    "        #tagged_c = MB_Column(X[key].copy(deep=True).tolist(),key)\n",
    "        append_dict={'name':key,'data':X[key].copy(deep=True).tolist()}\n",
    "        returnable.append(append_dict)\n",
    "    return returnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_names(dict_list):\n",
    "    print()\n",
    "    for item in dict_list:\n",
    "        print(item['name'],end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinAssoc(TargetNode, Xi,Z, fixedCondVars, X, alpha):\n",
    "    \n",
    "    min_assoc=999\n",
    "    #counter=0\n",
    "    #print(fixedCondVars)\n",
    "    if len(Z)==0:\n",
    "        #print(\"from minassoc1\")\n",
    "        #print(fixedCondVars)\n",
    "        min_assoc = Dep(TargetNode, Xi, fixedCondVars, X, alpha)\n",
    "        #counter+=1\n",
    "        subsetZ_min_assoc = fixedCondVars\n",
    "        #print(min_assoc)\n",
    "    else:\n",
    "        #print(2**len(Z)-1)\n",
    "        for IDsubsetZ_dec in range(0,2**len(Z)-1):\n",
    "            IDsubsetZ_bin = bin(IDsubsetZ_dec)\n",
    "            subsetZ = getZsubset(IDsubsetZ_bin,Z)\n",
    "            #print(len(Xi))\n",
    "            #print(\"from minassoc2\")\n",
    "            #print(IDsubsetZ_dec)\n",
    "            #print(subsetZ)\n",
    "            subsetZ_assoc=Dep(TargetNode, Xi, fixedCondVars+subsetZ,X,alpha)\n",
    "            #counter+=1\n",
    "            #print(subsetZ_assoc[IDsubsetZ_dec])\n",
    "            if subsetZ_assoc < min_assoc:\n",
    "                min_assoc = subsetZ_assoc\n",
    "                subsetZ_min_assoc = fixedCondVars + subsetZ\n",
    "                if (min_assoc==0):\n",
    "                    break\n",
    "    #print(\"Min Assoc module: \",counter)\n",
    "    return min_assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxMinHeuristic(TargetNode, CPC, Universe, X, alpha):\n",
    "    F=[]\n",
    "    assocF=-1\n",
    "    Z = CPC\n",
    "    fixedCondVars = []\n",
    "    if (len(CPC)>0):\n",
    "        Z = CPC[0:-1]           # all but the last one   \n",
    "        fixedCondVars = [CPC[-1]] # we use last one\n",
    "    for i in range(len(Universe)-1,-1,-1):\n",
    "        if (len(Universe[i])==0):\n",
    "            continue\n",
    "        assoc = MinAssoc(TargetNode,Universe[i],Z,fixedCondVars,X,alpha)\n",
    "        if (assoc>assocF):\n",
    "            assocF = assoc\n",
    "            F = Universe[i]\n",
    "        if (assoc==0):\n",
    "            Universe.pop(i)\n",
    "#     value_dict=[]    \n",
    "#     index_c = []\n",
    "#     for i in range(0,len(Universe)):\n",
    "#         index_c.append(i)\n",
    "#     while len(value_dict)<len(Universe):\n",
    "#         eval_index = random.randint(0,len(index_c)-1)\n",
    "#         print(\"\\nNode evaluating is: \"+Universe[index_c[eval_index]]['name'])\n",
    "#         value_dict.append([index_c[eval_index],MinAssoc(TargetNode,Universe[index_c[eval_index]], Z,fixedCondVars, X,alpha)])\n",
    "#         index_c.pop(eval_index)\n",
    "#         # Removing while looping is always best for performance\n",
    "#         print(\"Resulting value was: \"+str(value_dict[-1][1]))\n",
    "#         if value_dict[-1][1] == 0:\n",
    "#             # Remove node from Universe\n",
    "#             last_eval = value_dict[-1][0]\n",
    "#             Universe.pop(last_eval)\n",
    "#             value_dict.pop(-1)\n",
    "#             # Update index_c values\n",
    "#             for k in range(0,len(index_c)):\n",
    "#                 if index_c[k]>last_eval:\n",
    "#                     index_c[k]=index_c[k]-1\n",
    "#             # update value_dict\n",
    "#             for k in range(0,len(value_dict)):\n",
    "#                 if value_dict[k][0]>last_eval:\n",
    "#                     value_dict[k][0]=value_dict[k][0]-1\n",
    "    \n",
    "#     for i in range(0,len(value_dict)):\n",
    "#         if value_dict[i][1]>assocF:\n",
    "#             assocF=value_dict[i][1]\n",
    "#             F = Universe[value_dict[i][0]]\n",
    "        #print(F)\n",
    "    return [F,assocF,Universe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_CPC(CPC):\n",
    "    for i in CPC:\n",
    "        print(i['name']+\" \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMPC_(TargetNode,Universe,X,alpha):\n",
    "    \n",
    "    CPC=[]\n",
    "    #print(TargetNode)\n",
    "    # Phase I: Foward\n",
    "    print(\"Entering Phase I\")\n",
    "    print(\"MMPC_beggining: \\n\"+str(len(Universe)))\n",
    "    while len(Universe)>0:\n",
    "        CPC_old = list(CPC) # copy\n",
    "        maxminheur=MaxMinHeuristic(TargetNode,CPC,list(Universe),X,alpha)\n",
    "        # maxminheur = [F, assocF, Universe]\n",
    "        F = maxminheur[0]\n",
    "        assocF = maxminheur[1]\n",
    "        #print(assocF)\n",
    "        Universe = maxminheur[2]\n",
    "        #print(\"Universe printing line\")\n",
    "        #print(Universe)\n",
    "        #print(\"\\n=============================\")\n",
    "        #print(CPC)\n",
    "        if assocF > 0:\n",
    "            CPC.append(F)\n",
    "            indF=Universe.index(F)\n",
    "            Universe.pop(indF)\n",
    "        #if (len(CPC)==len(CPC_old)) or (len(CPC)>0.3*(len(Universe)-1)):\n",
    "        if (len(CPC)==len(CPC_old)):\n",
    "            break\n",
    "        print(\"\\nUniverse actual size:\")\n",
    "        print(len(Universe))\n",
    "        print(\"CPC actual size:\")\n",
    "        print(len(CPC))\n",
    "        print(\"CPC contents:\")\n",
    "        print_CPC(CPC)\n",
    "    \n",
    "    # Phase 2: Backward\n",
    "    print(\"\\nEntering Phase II\")\n",
    "    CPC=CPC[::-1]\n",
    "    if len(CPC)>1:\n",
    "        Z=list(CPC)\n",
    "        for i in range(len(CPC)-1,-1,-1):\n",
    "            # index is i\n",
    "            Z.pop(i)\n",
    "            #print(\"Analyzing D-separator for \",CPC[i]['name'])\n",
    "            if ExistDseparator(TargetNode,CPC[i],Z,X,alpha)[0] == True:\n",
    "                #print(\"it did exist! removing from cpc.\")\n",
    "                CPC.pop(i)\n",
    "#     return symmetry_test_v2(TargetNode,CPC,X,alpha)\n",
    "    return CPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMPC(TargetNode, X, alpha):\n",
    "    # The universe will be an array of DataFrame Columns\n",
    "    Universe = arrayUniverse(TargetNode,X)\n",
    "    print(len(Universe))\n",
    "    X = arrayX(X)\n",
    "    print(len(X))\n",
    "    for column in X:\n",
    "        if (column['name']==TargetNode):\n",
    "            TargetNode = column\n",
    "            break\n",
    "    CPC = MMPC_(TargetNode,Universe,X,alpha)\n",
    "    return CPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMPC_Parallel(arg):\n",
    "    TargetNode, X, alpha = arg\n",
    "    Universe = arrayUniverse(TargetNode,X)\n",
    "    print(len(Universe))\n",
    "    X = arrayX(X)\n",
    "    print(len(X))\n",
    "    for column in X:\n",
    "        if (column['name']==TargetNode):\n",
    "            TargetNode = column\n",
    "            break\n",
    "    CPC = MMPC_(TargetNode,Universe,X,alpha)\n",
    "    return CPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeysPartition(targetNode, data_keys,n_partitions):\n",
    "    n_partitions = int(np.log2(len(data_keys))/2)  # log2 ( number of variables ) divided by 2\n",
    "    partitions = []\n",
    "    partition_diff = int(int(len(data_keys)/n_partitions)/2)\n",
    "    for i in range(0,n_partitions):\n",
    "        if (i==0):\n",
    "            partitions.append(list(data_keys[-partition_diff::])+list(data_keys[0:int(len(data_keys)/n_partitions)]))\n",
    "            continue\n",
    "        if (i<n_partitions-1):\n",
    "            partitions.append(list(data_keys[-partition_diff+int(len(data_keys)/n_partitions)*i:int(len(data_keys)/n_partitions)*(i+1)]))\n",
    "            continue\n",
    "        if (i==n_partitions-1):\n",
    "            partitions.append(list(data_keys[-partition_diff+int(len(data_keys)/n_partitions)*i::]))\n",
    "            \n",
    "    for i in range(0,n_partitions):\n",
    "        for j in range(len(partitions[i])-1,-1,-1):\n",
    "            if (partitions[i][j]==targetNode):\n",
    "                partitions[i].pop(j)\n",
    "        partitions[i] = partitions[i] + [targetNode]\n",
    "    return partitions,n_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(keys_partitions[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================\n",
      "36\n",
      "37\n",
      "Entering Phase I\n",
      "MMPC_beggining: \n",
      "36\n",
      "\n",
      "Universe actual size:\n",
      "19\n",
      "CPC actual size:\n",
      "1\n",
      "CPC contents:\n",
      "Node29@3 \n",
      "Universe actual size:\n",
      "18\n",
      "CPC actual size:\n",
      "2\n",
      "CPC contents:\n",
      "Node29@3 Node27@2 \n",
      "Universe actual size:\n",
      "17\n",
      "CPC actual size:\n",
      "3\n",
      "CPC contents:\n",
      "Node29@3 Node27@2 Node26@3 \n",
      "Universe actual size:\n",
      "15\n",
      "CPC actual size:\n",
      "4\n",
      "CPC contents:\n",
      "Node29@3 Node27@2 Node26@3 Node22@4 \n",
      "Entering Phase II\n",
      "Target Node is:  Node1@4\n",
      "PC set is :\n",
      "Node22@4\n",
      "Node26@3\n",
      "CPU times: user 2min 9s, sys: 0 ns, total: 2min 9s\n",
      "Wall time: 2min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a20114261/anaconda3/envs/GeneInteractionsBN/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import precision_recall_fscore_support as full_score\n",
    "alpha=0.05\n",
    "# Initial vectors setup\n",
    "#const_vectors = setup_const_vectors(data_vars,data_c_size)\n",
    "#for i in range(0,len(X.keys())):    \n",
    "#for i in range(0,1):  \n",
    "print(\"======================================================================================\")\n",
    "\n",
    "TargetNode =X.keys()[0]\n",
    "PC=MMPC(TargetNode,X,alpha)\n",
    "print(\"Target Node is: \",TargetNode)\n",
    "print(\"PC set is :\")\n",
    "for j in PC:\n",
    "    print(j['name'])\n",
    "\n",
    "TargetNodeDict={}\n",
    "TargetNodeDict['name'] = TargetNode\n",
    "TargetNodeDict['data'] = X[TargetNode]\n",
    "clf = LinearSVC(random_state=0)\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "for i in range(0,data_c_size):\n",
    "    d_row = []\n",
    "    for pc_column in PC:\n",
    "        d_row.append(pc_column['data'][i])\n",
    "    X_test.append(d_row)\n",
    "for i in range(0,data_c_size):\n",
    "    Y_test.append(TargetNodeDict['data'][i])\n",
    "clf.fit(X_test[:-1000],Y_test[:-1000])\n",
    "full_score(Y_test[-1000:],clf.predict(X_test[-1000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [ 0.97        0.          0.86636971  0.        ]\n",
      "recall: [ 0.85840708  0.          0.9974359   0.        ]\n",
      "fscore: [ 0.91079812  0.          0.9272944   0.        ]\n",
      "support: [113  65 780  42]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a20114261/anaconda3/envs/GeneInteractionsBN/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "TargetNodeDict={}\n",
    "TargetNodeDict['name'] = TargetNode\n",
    "TargetNodeDict['data'] = X[TargetNode]\n",
    "clf = LinearSVC(random_state=0)\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "for i in range(0,data_c_size):\n",
    "    d_row = []\n",
    "    for pc_column in PC:\n",
    "        d_row.append(pc_column['data'][i])\n",
    "    X_test.append(d_row)\n",
    "for i in range(0,data_c_size):\n",
    "    Y_test.append(TargetNodeDict['data'][i])\n",
    "clf.fit(X_test[:-1000],Y_test[:-1000])\n",
    "precision, recall, fscore, support=full_score(Y_test[-1000:],clf.predict(X_test[-1000:]))\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a20114261/anaconda3/envs/GeneInteractionsBN/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_graph = pd.read_csv('./Alarm1_graph.txt',delimiter='  ',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_graph = X_graph.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def related_nodes(X_graph,X,ind):\n",
    "    print(\"Acoording to the true graph, the PC set for \",X.keys()[ind],\"is:\")\n",
    "    for i in range(0,len(X_graph[ind])):\n",
    "        if (X_graph[ind][i]==1):\n",
    "            print(X.keys()[i])\n",
    "    X_graph = X_graph.transpose()\n",
    "    for i in range(0,len(X_graph[ind])):\n",
    "        if (X_graph[ind][i]==1):\n",
    "            print(X.keys()[i])\n",
    "    X_graph = X_graph.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node1@4 is:\n",
      "Node22@4\n",
      "Node29@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node2@4 is:\n",
      "Node23@4\n",
      "Node27@2\n",
      "Node29@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node3@3 is:\n",
      "Node30@2\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node4@4 is:\n",
      "Node15@3\n",
      "Node22@4\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node5@3 is:\n",
      "Node6@2\n",
      "Node13@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node6@2 is:\n",
      "Node5@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node7@3 is:\n",
      "Node9@2\n",
      "Node13@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node8@3 is:\n",
      "Node9@2\n",
      "Node13@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node9@2 is:\n",
      "Node7@3\n",
      "Node8@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node10@3 is:\n",
      "Node12@3\n",
      "Node16@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node11@2 is:\n",
      "Node36@2\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node12@3 is:\n",
      "Node13@3\n",
      "Node34@3\n",
      "Node10@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node13@3 is:\n",
      "Node14@2\n",
      "Node5@3\n",
      "Node7@3\n",
      "Node8@3\n",
      "Node12@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node14@2 is:\n",
      "Node15@3\n",
      "Node16@3\n",
      "Node18@3\n",
      "Node31@2\n",
      "Node13@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node15@3 is:\n",
      "Node21@4\n",
      "Node4@4\n",
      "Node14@2\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node16@3 is:\n",
      "Node17@2\n",
      "Node10@3\n",
      "Node14@2\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node17@2 is:\n",
      "Node16@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node18@3 is:\n",
      "Node19@3\n",
      "Node28@2\n",
      "Node14@2\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node19@3 is:\n",
      "Node20@2\n",
      "Node21@4\n",
      "Node18@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node20@2 is:\n",
      "Node19@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node21@4 is:\n",
      "Node22@4\n",
      "Node29@3\n",
      "Node15@3\n",
      "Node19@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node22@4 is:\n",
      "Node23@4\n",
      "Node27@2\n",
      "Node29@3\n",
      "Node1@4\n",
      "Node4@4\n",
      "Node21@4\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node23@4 is:\n",
      "Node24@2\n",
      "Node25@4\n",
      "Node2@4\n",
      "Node22@4\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node24@2 is:\n",
      "Node23@4\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node25@4 is:\n",
      "Node26@3\n",
      "Node23@4\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node26@3 is:\n",
      "Node25@4\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node27@2 is:\n",
      "Node2@4\n",
      "Node22@4\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node28@2 is:\n",
      "Node29@3\n",
      "Node30@2\n",
      "Node18@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node29@3 is:\n",
      "Node1@4\n",
      "Node2@4\n",
      "Node21@4\n",
      "Node22@4\n",
      "Node28@2\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node30@2 is:\n",
      "Node3@3\n",
      "Node28@2\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node31@2 is:\n",
      "Node14@2\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node32@3 is:\n",
      "Node35@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node33@3 is:\n",
      "Node35@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node34@3 is:\n",
      "Node36@2\n",
      "Node37@2\n",
      "Node12@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node35@3 is:\n",
      "Node36@2\n",
      "Node37@2\n",
      "Node32@3\n",
      "Node33@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node36@2 is:\n",
      "Node11@2\n",
      "Node34@3\n",
      "Node35@3\n",
      "====================================================\n",
      "Acoording to the true graph, the PC set for  Node37@2 is:\n",
      "Node34@3\n",
      "Node35@3\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(X_graph.keys())):    \n",
    "    print(\"====================================================\")\n",
    "    related_nodes(X_graph,X,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Results for Node1 should { 2, 22, 23, 25 } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import gc\n",
    "import os\n",
    "import copy\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from random import randint\n",
    "from bisect import bisect\n",
    "from math import log, e\n",
    "from sklearn.feature_selection import mutual_info_classif as mi_clasf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading preselected nodes\n",
    "main_directory= '/home/a20114261/alarm_datasets/Alarm10/'\n",
    "save_folder='/home/a20114261/alarm_datasets/log_results/'\n",
    "\n",
    "if not os.path.exists(main_directory):\n",
    "    print(\"Bad routing.\")\n",
    "preselected_nodes=[] # will have [node_str,balance_ranking]\n",
    "# so far, we need Node, size of estimated pc set per filename, balance ranking\n",
    "ff = open(save_folder+'mmpc_partitioned/alarm10_binary_nodes_selected.txt','r')\n",
    "for e in ff.read().split('\\n'):\n",
    "    spl_line = e.split(';')\n",
    "    if (len(spl_line[0])==0):\n",
    "        continue\n",
    "    preselected_nodes.append([spl_line[0].split('@')[0],float(spl_line[1])])\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pc_size=[]\n",
    "ff = open(save_folder+'mmpc_partitioned/alarm10_binary_nodes_pc_size.txt','r')\n",
    "for e in ff.read().split('\\n'):\n",
    "    spl_line = e.split(';')\n",
    "    if (len(spl_line[0])==0):\n",
    "        continue\n",
    "    node_pc_size.append([spl_line[0],spl_line[1],int(spl_line[2])])\n",
    "ff.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_heads = []\n",
    "for i in range(1,371):\n",
    "    graph_heads.append('Node'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_score = mi_clasf(X, X[X.keys()[1]],discrete_features=True)\n",
    "print(len(mi_score))\n",
    "for e in mi_score:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alpha=0.05\n",
    "print(\"======================================================================================\")\n",
    "print(\"Entropy-Based Mutual Information Evaluation\")\n",
    "print(\"======================================================================================\")\n",
    "\n",
    "\n",
    "pre_PCs=[]\n",
    "for filename in os.listdir(main_directory):\n",
    "    for node in [x[0] for x in preselected_nodes]:\n",
    "        PobDict={}\n",
    "        PobDict['TargetNode']=node\n",
    "        PobDict['filename']=filename\n",
    "        pre_PCs.append(PobDict)\n",
    "\n",
    "\n",
    "PCs = Parallel(n_jobs=40)(map(delayed(EntropyBasedMI),pre_PCs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "prescored_PCs=[]\n",
    "for e in PCs:\n",
    "    pc_length = [x[2] for x in node_pc_size if x[0]==e['filename'] and x[1].split('@')[0]==e['TargetNode']]\n",
    "    if (len(pc_length)==0):\n",
    "        e['PC']=[]\n",
    "        continue\n",
    "    e['PC']= [x[0] for x in sorted(e['evaluated_nodes'],key=itemgetter(1),reverse=True)[:pc_length[0]]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# evaluation for each node, using each file as training set, in parallel\n",
    "print(\"======================================================================================\")\n",
    "print(\"Entropy-Based Mutual Information Scoring phase\")\n",
    "print(\"======================================================================================\")\n",
    "\n",
    "PC_mean_score = Parallel(n_jobs=40)(map(delayed(CandidateScore_Parallel),PCs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3899"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory=\"/home/a20114261/alarm_datasets/log_results/mmpc_partitioned\"\n",
    "ff = open(log_directory+'/scored_entropy-mi_log.txt','w')\n",
    "for e in sorted(PC_mean_score, key=itemgetter('filename'),reverse=True):\n",
    "    ff.write(e['filename']+';')\n",
    "    ff.write(e['TargetNode']+';')\n",
    "    for node in e['PC']:\n",
    "        ff.write(node+'_')\n",
    "    ff.write(';')\n",
    "    for class_pred in e['class_precisions']:\n",
    "            ff.write(class_pred[1]+'_')\n",
    "            for arr_acc in class_pred[0]:\n",
    "                ff.write(str(arr_acc[0])+'\\t')\n",
    "                ff.write(str(arr_acc[1])+'\\t')\n",
    "                ff.write(str(arr_acc[2])+'\\t')\n",
    "            ff.write('_')\n",
    "    ff.write('\\n')\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EntropyBasedMI(PobDict):\n",
    "    X = pd.read_csv(main_directory+'/'+filename,delimiter='  ',header=None)\n",
    "    X.columns = graph_heads\n",
    "    mi_score = mi_clasf(X, X[PobDict['TargetNode']],discrete_features=True)\n",
    "    PobDict['evaluated_nodes']=[]\n",
    "    for i in range(0,len(mi_score)):\n",
    "        if i == (int(PobDict['TargetNode'].split('Node')[1])-1):\n",
    "            continue\n",
    "        PobDict['evaluated_nodes'].append(['Node'+str(i+1),mi_score[i]])\n",
    "    print('Exiting Entropy-based Mutual Information analysis for '+PobDict['TargetNode']+' with file '+PobDict['filename'])\n",
    "    return PobDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CandidateScore_Parallel(PobDict):\n",
    "    global x_heads_train\n",
    "\n",
    "    # training and scoring\n",
    "    X_train_df = pd.read_csv(main_directory+PobDict['filename'],delimiter='  ',header=None)\n",
    "    X_train_df.columns=graph_heads\n",
    "    \n",
    "    #X_train, X_test, Y_train, Y_test = train_test_split(X_train_df, X_train_df[TargetEvalNode], test_size=0.1, random_state=0)\n",
    "    \n",
    "    X_train = X_train_df\n",
    "    Y_train = X_train_df[PobDict['TargetNode']]\n",
    "    \n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train[PobDict['PC']],Y_train)\n",
    "    \n",
    "    PobDict['class_precisions']=[]\n",
    "    for filename in [x for x in os.listdir(main_directory) if x.split('_')[1]==PobDict['filename'].split('_')[1]]:\n",
    "        print(len([x for x in os.listdir(main_directory) if x.split('_')[1]==PobDict['filename'].split('_')[1]]))\n",
    "        if (filename == PobDict['filename']):\n",
    "            continue\n",
    "        print(\"*****\")\n",
    "        print()\n",
    "        print(\"Testing on dataset: \"+filename)\n",
    "        X_test = pd.read_csv(main_directory+filename,delimiter='  ',header=None)\n",
    "        X_test.columns = graph_heads\n",
    "        \n",
    "\n",
    "        # get score values\n",
    "        precision = []\n",
    "        values_counter=set(X_train_df[PobDict['TargetNode']])\n",
    "        for val in values_counter:\n",
    "            #Y_pred_c = clf.predict(X_train_df.query( TargetEvalNode+'== '+str(i))[PobDict['supercpc']][-100:])\n",
    "            if (len(X_test.query( PobDict['TargetNode']+'== '+str(val)))==0):\n",
    "                precision.append([val,0,0])\n",
    "                continue\n",
    "            Y_pred_c = clf.predict(X_test.query( PobDict['TargetNode']+'== '+str(val))[PobDict['PC']])\n",
    "            precision.append([val,len(Y_pred_c),Y_pred_c.tolist().count(val)/len(Y_pred_c)])\n",
    "\n",
    "        for e in range(0,len(precision)):\n",
    "            print('precision for class '+str(precision[e][0])+' with '+str(precision[e][1])+' samples in dataset : '+str(precision[e][2]))\n",
    "    \n",
    "        print(\"G-mean score: \"+str(g_mean(precision)))\n",
    "        print(\"*****\")\n",
    "        print()\n",
    "        #print(clf.score(X_test[PobDict['supercpc'][:10]],Y_test))\n",
    "        PobDict['class_precisions'].append([precision,filename])\n",
    "    return PobDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_scoring(size1, size2):\n",
    "    f_size1 = float(size1)\n",
    "    f_size2 = float(size2)\n",
    "    if (f_size1/f_size2 <= 1):\n",
    "        return f_size1/f_size2\n",
    "    else:\n",
    "        return f_size2/f_size1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_mean(precision_arr):\n",
    "    counter=1\n",
    "    for e in precision_arr:\n",
    "        counter=counter*e[2]\n",
    "    \n",
    "    return counter**(1/len(precision_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
